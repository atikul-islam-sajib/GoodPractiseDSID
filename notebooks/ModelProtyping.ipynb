{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/atikul-islam-sajib/GoodPractiseDSID.git\n",
    "\n",
    "%cd /content/GoodPractiseDSID/\n",
    "\n",
    "%pwd\n",
    "\n",
    "!python alzheimer/data/data_loader.py --dataset /content/dataset.zip\n",
    "\n",
    "\n",
    "from alzheimer.features.build_features import FeatureBuilder\n",
    "\n",
    "from alzheimer.data.data_loader import Dataloader\n",
    "\n",
    "loader = Dataloader(\"/content/dataset.zip\")\n",
    "\n",
    "loader.unzip_dataset()\n",
    "\n",
    "build_features = FeatureBuilder()\n",
    "build_features.build_feature()\n",
    "\n",
    "loader.extract_feature()\n",
    "\n",
    "import torch\n",
    "\n",
    "train_loader = torch.load(\"/content/GoodPractiseDSID/data/processed/train_loader.pth\")\n",
    "\n",
    "train = 0\n",
    "\n",
    "for data, label in train_loader:\n",
    "  train = train + data.shape[0]\n",
    "\n",
    "print(train)\n",
    "\n",
    "a = torch.load(\"/content/GoodPractiseDSID/data/processed/test_loader.pth\")\n",
    "len(a)\n",
    "\n",
    "test_loader = torch.load(\"/content/GoodPractiseDSID/data/processed/test_loader.pth\")\n",
    "\n",
    "test = 0\n",
    "\n",
    "for data, label in test_loader:\n",
    "  test = test + data.shape[0]\n",
    "\n",
    "print(test)\n",
    "\n",
    "train + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check done\n"
     ]
    }
   ],
   "source": [
    "print(\"check done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shahmuhammadraditrahman/Desktop/GoodPractiseDSID\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/shahmuhammadraditrahman/Desktop/GoodPractiseDSID/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alzheimer.data.data_loader import Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For mac\n",
    "import torch\n",
    "\n",
    "'cuda' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For NVDIA\n",
    "\n",
    "\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n",
      "Using MPS device for computations\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS (Apple Silicon GPU support) is available\n",
    "mps_available = torch.backends.mps.is_available()\n",
    "\n",
    "# Print whether MPS is available or not\n",
    "print(\"MPS available:\", mps_available)\n",
    "# If MPS is available, set the device to MPS for GPU computations\n",
    "if mps_available:\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS device for computations\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU for computations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python alzheimer/data/data_loader.py --dataset /Users/shahmuhammadraditrahman/Desktop/dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(256, 128, 0.0), (128, 64, 0.4), (64, 16, 0.3), (16, 3)][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alzheimer.models.model import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier()\n",
    "\n",
    "# print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable params: 1315217\n"
     ]
    }
   ],
   "source": [
    "trainable_params = 0\n",
    "\n",
    "for _, params in clf.named_parameters():\n",
    "    trainable_params += params.numel()\n",
    "\n",
    "print(f\"Total trainable params: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alzheimer.models.train_model import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cla\n",
    "\n",
    "\n",
    "trainer = Trainer(classifier=clf.to(device),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/torch/autograd/__init__.py:251: UserWarning: Error detected in LinearBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/traitlets/config/application.py\", line 1077, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 737, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/_6/fpk79cm53rxgcj2gh5prtww00000gn/T/ipykernel_3773/1008373765.py\", line 1, in <module>\n",
      "    trainer.train(epochs=1, train_loader=None, test_loader=None)\n",
      "  File \"/Users/shahmuhammadraditrahman/Desktop/GoodPractiseDSID/alzheimer/models/train_model.py\", line 129, in train\n",
      "    model1, model2, model3 = self.classifier(X_train_batch)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/shahmuhammadraditrahman/Desktop/GoodPractiseDSID/alzheimer/models/model.py\", line 184, in forward\n",
      "    combined = self.combined_layer(concat)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/shahmuhammadraditrahman/anaconda3/envs/alzheimer/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      " (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1699448801785/work/torch/csrc/autograd/python_anomaly_mode.cpp:119.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [MPSFloatType [256, 4720]] is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/shahmuhammadraditrahman/Desktop/GoodPractiseDSID/notebooks/ModelProtyping.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/shahmuhammadraditrahman/Desktop/GoodPractiseDSID/notebooks/ModelProtyping.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, train_loader\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, test_loader\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Desktop/GoodPractiseDSID/alzheimer/models/train_model.py:144\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, epochs, train_loader, test_loader)\u001b[0m\n\u001b[1;32m    137\u001b[0m model3_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_model_loss(\n\u001b[1;32m    138\u001b[0m     model3, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel3_loss_function, y_train_batch\n\u001b[1;32m    139\u001b[0m )\n\u001b[1;32m    141\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_back_propagation(\n\u001b[1;32m    142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel1_optimizer, model1_loss, retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    143\u001b[0m )\n\u001b[0;32m--> 144\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_back_propagation(\n\u001b[1;32m    145\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel2_optimizer, model2_loss, retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    146\u001b[0m )\n\u001b[1;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_back_propagation(\n\u001b[1;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel3_optimizer, model3_loss, retain_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m model1_predicted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_predicted_label(model1)\n",
      "File \u001b[0;32m~/Desktop/GoodPractiseDSID/alzheimer/models/train_model.py:58\u001b[0m, in \u001b[0;36mTrainer._do_back_propagation\u001b[0;34m(self, optimizer, model_loss, retain_graph)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_back_propagation\u001b[39m(\u001b[39mself\u001b[39m, optimizer, model_loss, retain_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     57\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 58\u001b[0m     model_loss\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49mretain_graph)\n\u001b[1;32m     59\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/alzheimer/lib/python3.9/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/alzheimer/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [MPSFloatType [256, 4720]] is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "trainer.train(epochs=1, train_loader=None, test_loader=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960 1960\n"
     ]
    }
   ],
   "source": [
    "check = torch.load(\"/Users/shahmuhammadraditrahman/Desktop/GoodPractiseDSID/data/processed/test_loader.pth\")\n",
    "\n",
    "td = 0\n",
    "tl = 0\n",
    "for data, label in check:\n",
    "    td = td + data.shape[0]\n",
    "    tl = tl + label.shape[0]\n",
    "    \n",
    "print(td, tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5879 5879\n"
     ]
    }
   ],
   "source": [
    "check = torch.load(\n",
    "    \"/Users/shahmuhammadraditrahman/Desktop/GoodPractiseDSID/data/processed/train_loader.pth\"\n",
    ")\n",
    "\n",
    "td = 0\n",
    "tl = 0\n",
    "for data, label in check:\n",
    "    td = td + data.shape[0]\n",
    "    tl = tl + label.shape[0]\n",
    "\n",
    "print(td, tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alzheimer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
